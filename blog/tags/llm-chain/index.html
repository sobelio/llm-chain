<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-tags-post-list-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.0">
<title data-rh="true">4 posts tagged with &quot;llm-chain&quot; | llm-chain</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://docs.llm-chain.xyz/img/llmchainsocial.png"><meta data-rh="true" name="twitter:image" content="https://docs.llm-chain.xyz/img/llmchainsocial.png"><meta data-rh="true" property="og:url" content="https://docs.llm-chain.xyz/blog/tags/llm-chain"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" property="og:title" content="4 posts tagged with &quot;llm-chain&quot; | llm-chain"><meta data-rh="true" name="docusaurus_tag" content="blog_tags_posts"><meta data-rh="true" name="docsearch:docusaurus_tag" content="blog_tags_posts"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://docs.llm-chain.xyz/blog/tags/llm-chain"><link data-rh="true" rel="alternate" href="https://docs.llm-chain.xyz/blog/tags/llm-chain" hreflang="en"><link data-rh="true" rel="alternate" href="https://docs.llm-chain.xyz/blog/tags/llm-chain" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="llm-chain RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="llm-chain Atom Feed">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CVN7CRKQ8Z"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-CVN7CRKQ8Z",{anonymize_ip:!0})</script>


<script src="https://embed.lu.ma/checkout-button.js" async defer="defer"></script><link rel="stylesheet" href="/assets/css/styles.ac2ffb12.css">
<link rel="preload" href="/assets/js/runtime~main.1993ec7f.js" as="script">
<link rel="preload" href="/assets/js/main.29f220da.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/llmchain.svg" alt="llm-chain-logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/llmchain.svg" alt="llm-chain-logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">llm-chain</b></a><a class="navbar__item navbar__link" href="/docs/introduction">Documentation</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/sobelio/llm-chain" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2023/04/28/parsing-llm-input-with-llm-chain-0-8-2">Announcement: LLM Chain Update 0.8.2</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/2023/04/27/index">Introducing v0.8.1: Enhanced Prompt Macro and New Conversational Chain Type</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/introducing-llm-chain-v080">Introducing LLM-chain v0.8.0 - Expanding the prompt system</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/introducing-llm-chain-v060">Introducing LLM-chain v0.6.0: Powerful Templating and Improved Prompt System</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/using-chatgpt-in-rust">Using ChatGPT in Rust with llm-chain</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><header class="margin-bottom--xl"><h1>4 posts tagged with &quot;llm-chain&quot;</h1><a href="/blog/tags">View All Tags</a></header><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/introducing-llm-chain-v080">Introducing LLM-chain v0.8.0 - Expanding the prompt system</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-04-26T00:00:00.000Z" itemprop="datePublished">April 26, 2023</time> · <!-- -->2 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/williamhogman.png" alt="will rudenmalm"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">will rudenmalm</span></a></div><small class="avatar__subtitle" itemprop="description">making llm-chain</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>We&#x27;re excited to announce the release of llm-chain v0.8.0, a significant update to our LLM library. This release introduces a host of improvements and new features, including a completely revamped Prompt system and more streamlined handling of Parameters. Let&#x27;s dive into the details!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="revamped-prompt-system">Revamped Prompt System<a href="#revamped-prompt-system" class="hash-link" aria-label="Direct link to Revamped Prompt System" title="Direct link to Revamped Prompt System">​</a></h2><p>Our new Prompt system has been redesigned from the ground up to provide greater flexibility and efficiency in working with language models. In llm-chain v0.8.0, we&#x27;ve introduced new structs and enums to better represent chat messages and their roles, such as ChatMessage, ChatMessageCollection, and ChatRole. The Data enum has also been introduced to represent either a collection of chat messages or a single text, making it easier to work with different types of data.</p><p>Furthermore, we&#x27;ve created a more powerful PromptTemplate system that allows you to format prompts with a set of parameters. This enables you to dynamically generate prompts for your language models without the need for cumbersome string manipulation.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="executors-no-longer-handle-parameters">Executors No Longer Handle Parameters<a href="#executors-no-longer-handle-parameters" class="hash-link" aria-label="Direct link to Executors No Longer Handle Parameters" title="Direct link to Executors No Longer Handle Parameters">​</a></h2><p>With the release of llm-chain v0.8.0, we&#x27;ve shifted the responsibility of handling Parameters from the executors to the main llm-chain crate. This change simplifies the process of working with executors, allowing developers to focus more on the core functionality of their language models.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="whats-next">What&#x27;s Next?<a href="#whats-next" class="hash-link" aria-label="Direct link to What&#x27;s Next?" title="Direct link to What&#x27;s Next?">​</a></h2><p>This release marks a significant step forward in the evolution. However, we&#x27;re not stopping here! We&#x27;ll continue to refine and expand the capabilities of llm-chain, making it even more powerful and user-friendly.</p><p>We encourage you to check out llm-chain v0.8.0 and experience the benefits of the improved Prompt system and streamlined handling of Parameters. As always, we appreciate your feedback and contributions to help make llm-chain the best language model library out there.</p><p>Upgrade to llm-chain v0.8.0 today and take your language models to the next level!</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm-chain">llm-chain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/update">update</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/large-language-models">large language models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/rust">rust</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/tera">tera</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/templating">templating</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/prompt-system">prompt system</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/introducing-llm-chain-v060">Introducing LLM-chain v0.6.0: Powerful Templating and Improved Prompt System</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-04-17T00:00:00.000Z" itemprop="datePublished">April 17, 2023</time> · <!-- -->2 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/williamhogman.png" alt="will rudenmalm"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">will rudenmalm</span></a></div><small class="avatar__subtitle" itemprop="description">making llm-chain</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>We are thrilled to announce the release of llm-chain v0.6.0, which introduces significant enhancements to our library. This update focuses on making the llm-chain more robust and versatile, allowing developers to build even more advanced applications with ease.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="major-updates">Major updates<a href="#major-updates" class="hash-link" aria-label="Direct link to Major updates" title="Direct link to Major updates">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-the-switch-to-the-tera-template-language">1. The switch to the <code>tera</code> template language<a href="#1-the-switch-to-the-tera-template-language" class="hash-link" aria-label="Direct link to 1-the-switch-to-the-tera-template-language" title="Direct link to 1-the-switch-to-the-tera-template-language">​</a></h4><p>One of the most significant changes in this release is the introduction of the <code>tera</code> template language. This powerful and flexible templating system enables developers to create dynamic and complex templates for their projects. The <code>tera</code> language allows for more advanced control structures and filters, making it a substantial upgrade from the previous templating system.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="2-improved-prompt-system">2. Improved prompt system<a href="#2-improved-prompt-system" class="hash-link" aria-label="Direct link to 2. Improved prompt system" title="Direct link to 2. Improved prompt system">​</a></h4><p>Another notable update is the revamped prompt system. With llm-chain v0.6.0, the prompt system now supports both Chat and completion-style models. This improvement means developers no longer need to worry about whether they are using a completion or chat model when crafting prompts. This unified approach simplifies the development process and makes it easier to work with various types of language models.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="3-updated-llamacpp">3. Updated LLaMA.cpp<a href="#3-updated-llamacpp" class="hash-link" aria-label="Direct link to 3. Updated LLaMA.cpp" title="Direct link to 3. Updated LLaMA.cpp">​</a></h4><p>The latest version of LLaMA.cpp has been integrated into this release, ensuring better performance and stability for your projects.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="other-improvements">Other improvements<a href="#other-improvements" class="hash-link" aria-label="Direct link to Other improvements" title="Direct link to Other improvements">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="1-safer-error-handling">1. Safer error handling<a href="#1-safer-error-handling" class="hash-link" aria-label="Direct link to 1. Safer error handling" title="Direct link to 1. Safer error handling">​</a></h4><p>In addition to the major updates, llm-chain v0.6.0 also brings improvements to error handling. Templates now return <code>Result</code> rather than panicking on errors, making it more convenient to handle any issues that may arise during development. Similarly, Executors also return <code>Result</code> instead of panicking on errors, providing a more consistent and safer API.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="time-to-move-on-from-the-old-templating-system">Time to move on from the old templating system<a href="#time-to-move-on-from-the-old-templating-system" class="hash-link" aria-label="Direct link to Time to move on from the old templating system" title="Direct link to Time to move on from the old templating system">​</a></h3><p>With the introduction of the <code>tera</code> template language, we strongly recommend moving away from the old templating system. This update provides a solid foundation for building even more advanced applications using the llm-chain library.</p><p>We hope you&#x27;re as excited about these enhancements as we are! As always, we appreciate your feedback and support. If you have any questions or need help, please don&#x27;t hesitate to reach out on <a href="https://discord.gg/kewN9Gtjt2" target="_blank" rel="noopener noreferrer">Discord</a> !</p><p>Happy coding! 🚀</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm-chain">llm-chain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/update">update</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/large-language-models">large language models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/rust">rust</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/tera">tera</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/templating">templating</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/prompt-system">prompt system</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/using-chatgpt-in-rust">Using ChatGPT in Rust with llm-chain</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-04-14T00:00:00.000Z" itemprop="datePublished">April 14, 2023</time> · <!-- -->2 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/williamhogman.png" alt="will rudenmalm"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">will rudenmalm</span></a></div><small class="avatar__subtitle" itemprop="description">making llm-chain</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>In this blog post, we&#x27;ll explore how to use ChatGPT in Rust with the help of the <code>llm-chain</code> library. We will walk through a simple example that demonstrates how to generate responses using OpenAI&#x27;s ChatGPT model.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started">Getting Started<a href="#getting-started" class="hash-link" aria-label="Direct link to Getting Started" title="Direct link to Getting Started">​</a></h2><p>First, let&#x27;s start by installing the necessary packages using <code>cargo add</code>. You will need the <code>llm-chain</code> and <code>llm-chain-openai</code> libraries:</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">cargo add llm-chain llm-chain-openai</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Now, let&#x27;s dive into the code:</p><div class="language-rust codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-rust codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">use</span><span class="token plain"> </span><span class="token namespace" style="opacity:0.7">llm_chain</span><span class="token namespace punctuation" style="opacity:0.7;color:#393A34">::</span><span class="token punctuation" style="color:#393A34">{</span><span class="token namespace" style="opacity:0.7">traits</span><span class="token namespace punctuation" style="opacity:0.7;color:#393A34">::</span><span class="token class-name">StepExt</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">Parameters</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">use</span><span class="token plain"> </span><span class="token namespace" style="opacity:0.7">llm_chain_openai</span><span class="token namespace punctuation" style="opacity:0.7;color:#393A34">::</span><span class="token namespace" style="opacity:0.7">chatgpt</span><span class="token namespace punctuation" style="opacity:0.7;color:#393A34">::</span><span class="token punctuation" style="color:#393A34">{</span><span class="token class-name">Executor</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">Model</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">Role</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token class-name">Step</span><span class="token punctuation" style="color:#393A34">}</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token attribute attr-name" style="color:#00a4db">#[tokio::main(flavor = </span><span class="token attribute attr-name string" style="color:#e3116c">&quot;current_thread&quot;</span><span class="token attribute attr-name" style="color:#00a4db">)]</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token keyword" style="color:#00009f">async</span><span class="token plain"> </span><span class="token keyword" style="color:#00009f">fn</span><span class="token plain"> </span><span class="token function-definition function" style="color:#d73a49">main</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">{</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">let</span><span class="token plain"> exec </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token class-name">Executor</span><span class="token punctuation" style="color:#393A34">::</span><span class="token function" style="color:#d73a49">new_default</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">let</span><span class="token plain"> chain </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> </span><span class="token class-name">Step</span><span class="token punctuation" style="color:#393A34">::</span><span class="token function" style="color:#d73a49">new</span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token class-name">Model</span><span class="token punctuation" style="color:#393A34">::</span><span class="token class-name">ChatGPT3_5Turbo</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">[</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">(</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token class-name">Role</span><span class="token punctuation" style="color:#393A34">::</span><span class="token class-name">System</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token string" style="color:#e3116c">&quot;You are a helpful assistant&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token punctuation" style="color:#393A34">(</span><span class="token class-name">Role</span><span class="token punctuation" style="color:#393A34">::</span><span class="token class-name">User</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;Tell me about the Rust programming language&quot;</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token punctuation" style="color:#393A34">]</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">to_chain</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token keyword" style="color:#00009f">let</span><span class="token plain"> res </span><span class="token operator" style="color:#393A34">=</span><span class="token plain"> chain</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">run</span><span class="token punctuation" style="color:#393A34">(</span><span class="token class-name">Parameters</span><span class="token punctuation" style="color:#393A34">::</span><span class="token function" style="color:#d73a49">new</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;</span><span class="token plain">exec</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">.</span><span class="token keyword" style="color:#00009f">await</span><span class="token punctuation" style="color:#393A34">.</span><span class="token function" style="color:#d73a49">unwrap</span><span class="token punctuation" style="color:#393A34">(</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token macro property" style="color:#36acaa">println!</span><span class="token punctuation" style="color:#393A34">(</span><span class="token string" style="color:#e3116c">&quot;{:?}&quot;</span><span class="token punctuation" style="color:#393A34">,</span><span class="token plain"> res</span><span class="token punctuation" style="color:#393A34">)</span><span class="token punctuation" style="color:#393A34">;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token punctuation" style="color:#393A34">}</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>In the code snippet above, we begin by importing the necessary modules and functions from the <code>llm-chain</code> and <code>llm-chain-openai</code> libraries. We then define a simple <code>main</code> function that uses the <code>Executor</code> and <code>Step</code> structs to create a conversational chain.</p><p>The <code>Model::ChatGPT3_5Turbo</code> model is used as the language model in this example. We also define two steps in the conversation: the first one sets the role of the assistant and the second one asks a question about the Rust programming language.</p><p>Finally, we execute the conversation chain using the <code>run</code> method and print the generated response.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="wrapping-up">Wrapping Up<a href="#wrapping-up" class="hash-link" aria-label="Direct link to Wrapping Up" title="Direct link to Wrapping Up">​</a></h2><p>As you can see, using ChatGPT in Rust with <code>llm-chain</code> is a straightforward and efficient process. The library makes it easy to build and manage conversational agents in Rust, allowing developers to focus on creating more powerful and interactive applications.</p><p>To continue learning about ChatGPT in Rust and how to make the most of the <code>llm-chain</code> library, try our <a href="https://chat.openai.com/docs/getting-started-tutorial/index" target="_blank" rel="noopener noreferrer">tutorial</a> .</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm-chain">llm-chain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/introduction">introduction</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/chatgpt">chatgpt</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/rust">rust</a></li></ul></div></footer></article><article class="margin-bottom--xl" itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h2 class="title_f1Hy" itemprop="headline"><a itemprop="url" href="/blog/introducing-llm-chain">Unleashing the Power of Large Language Models with LLM-chain</a></h2><div class="container_mt6G margin-vert--md"><time datetime="2023-04-10T00:00:00.000Z" itemprop="datePublished">April 10, 2023</time> · <!-- -->2 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/williamhogman.png" alt="will rudenmalm"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/williamhogman" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">will rudenmalm</span></a></div><small class="avatar__subtitle" itemprop="description">making llm-chain</small></div></div></div></div></header><div class="markdown" itemprop="articleBody"><p>We&#x27;re excited to announce the release of LLM-chain, a Rust library designed to help developers work with Large Language Models (LLMs) more effectively. Our primary focus is on providing robust support for prompt templates and chaining together prompts in multi-step chains, enabling complex tasks that LLMs can&#x27;t handle in a single step. This includes, but is not limited to, summarizing lengthy texts or performing advanced data processing tasks.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="features-of-llm-chain">Features of LLM-chain<a href="#features-of-llm-chain" class="hash-link" aria-label="Direct link to Features of LLM-chain" title="Direct link to Features of LLM-chain">​</a></h2><p>LLM-chain comes with a variety of features that make it easier to work with LLMs, including:</p><ul><li><strong>Prompt templates</strong>: Create reusable and easily customizable prompt templates for consistent and structured interactions with LLMs.</li><li><strong>Chains</strong>: Build powerful chains of prompts that allow you to execute more complex tasks, step by step, leveraging the full potential of LLMs.</li><li><strong>ChatGPT support</strong>: Currently supports ChatGPT models, with plans to add support for more LLMs in the future, such as LLaMa and Stanford&#x27;s Alpaca models.</li><li><strong>Tools</strong>: Enhance your AI agents&#x27; capabilities by giving them access to various tools, such as running Bash commands, executing Python scripts, or performing web searches, enabling more complex and powerful interactions.</li><li><strong>Extensibility</strong>: Designed with extensibility in mind, making it easy to integrate additional LLMs as the ecosystem grows and new models are developed.</li><li><strong>Community-driven</strong>: We welcome and encourage contributions from the community to help improve and expand the capabilities of LLM-chain.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="connect-with-us">Connect with Us<a href="#connect-with-us" class="hash-link" aria-label="Direct link to Connect with Us" title="Direct link to Connect with Us">​</a></h2><p>If you have any questions, suggestions, or feedback, feel free to join our <a href="https://discord.gg/kewN9Gtjt2" target="_blank" rel="noopener noreferrer">Discord community</a>. We&#x27;re always excited to hear from our users and learn about your experiences with LLM-chain.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started-with-llm-chain">Getting Started with LLM-chain<a href="#getting-started-with-llm-chain" class="hash-link" aria-label="Direct link to Getting Started with LLM-chain" title="Direct link to Getting Started with LLM-chain">​</a></h2><p>Check out our <a href="https://github.com/sobelio/llm-chain" target="_blank" rel="noopener noreferrer">Github repository</a> or the <a href="https://docs.rs/llm-chain" target="_blank" rel="noopener noreferrer">documentation</a> to get started.</p></div><footer class="row docusaurus-mt-lg"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/llm-chain">llm-chain</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/introduction">introduction</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/large-language-models">large language models</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/rust">rust</a></li></ul></div></footer></article><nav class="pagination-nav" aria-label="Blog list page navigation"></nav></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/introduction">Introduction</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.gg/kewN9Gtjt2" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/sobelio/llm-chain" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a class="footer__link-item" href="/llmcasual">Events</a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://docs.rs/llm-chain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docs.rs<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://crates.io/crates/llm-chain" target="_blank" rel="noopener noreferrer" class="footer__link-item">Crates.io<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://sobel.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">Sobel.io<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 - sobel.io</div></div></div></footer><button aria-label="Chat" class="EnhancedChat EnhancedChat__large EnhancedChat__round EnhancedChat__Visible"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><path fill="none" stroke-linecap="round" stroke-miterlimit="10" stroke-width="32" d="M87.48 380c1.2-4.38-1.43-10.47-3.94-14.86a42.63 42.63 0 00-2.54-3.8 199.81 199.81 0 01-33-110C47.64 139.09 140.72 48 255.82 48 356.2 48 440 117.54 459.57 209.85a199 199 0 014.43 41.64c0 112.41-89.49 204.93-204.59 204.93-18.31 0-43-4.6-56.47-8.37s-26.92-8.77-30.39-10.11a31.14 31.14 0 00-11.13-2.07 30.7 30.7 0 00-12.08 2.43L81.5 462.78a15.92 15.92 0 01-4.66 1.22 9.61 9.61 0 01-9.58-9.74 15.85 15.85 0 01.6-3.29z"></path><circle cx="160" cy="256" r="32"></circle><circle cx="256" cy="256" r="32"></circle><circle cx="352" cy="256" r="32"></circle></svg></button></div>
<script src="/assets/js/runtime~main.1993ec7f.js"></script>
<script src="/assets/js/main.29f220da.js"></script>
</body>
</html>