"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[7325],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>h});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),u=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=u(e.components);return r.createElement(s.Provider,{value:t},e.children)},c="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},g=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=u(n),g=a,h=c["".concat(s,".").concat(g)]||c[g]||d[g]||i;return n?r.createElement(h,o(o({ref:t},p),{},{components:n})):r.createElement(h,o({ref:t},p))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=g;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[c]="string"==typeof e?e:a,o[1]=l;for(var u=2;u<i;u++)o[u]=n[u];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}g.displayName="MDXCreateElement"},3748:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>d,frontMatter:()=>i,metadata:()=>l,toc:()=>u});var r=n(7462),a=(n(7294),n(3905));const i={},o="Setting up a project with llm-chain",l={unversionedId:"getting-started-tutorial/setting-up-a-project",id:"getting-started-tutorial/setting-up-a-project",title:"Setting up a project with llm-chain",description:"Having problems? Don't worry, reach out on discord and we will help you out.",source:"@site/docs/getting-started-tutorial/01-setting-up-a-project.md",sourceDirName:"getting-started-tutorial",slug:"/getting-started-tutorial/setting-up-a-project",permalink:"/docs/getting-started-tutorial/setting-up-a-project",draft:!1,editUrl:"https://github.com/sobelio/llm-chain/tree/main/docs/docs/getting-started-tutorial/01-setting-up-a-project.md",tags:[],version:"current",sidebarPosition:1,frontMatter:{},sidebar:"sidebar",previous:{title:"Getting started",permalink:"/docs/getting-started-tutorial/index"},next:{title:"Generating Your First LLM Output",permalink:"/docs/getting-started-tutorial/generating-your-first-llm-output"}},s={},u=[{value:"Installing Rust",id:"installing-rust",level:2},{value:"Creating a New Rust Project",id:"creating-a-new-rust-project",level:2},{value:"Installing LLM-Chain",id:"installing-llm-chain",level:2},{value:"Choosing a Driver: LLAMA vs OpenAI",id:"choosing-a-driver-llama-vs-openai",level:2}],p={toc:u},c="wrapper";function d(e){let{components:t,...n}=e;return(0,a.kt)(c,(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"setting-up-a-project-with-llm-chain"},"Setting up a project with llm-chain"),(0,a.kt)("admonition",{type:"tip"},(0,a.kt)("p",{parentName:"admonition"},"Having problems? Don't worry, reach out on ",(0,a.kt)("a",{parentName:"p",href:"https://discord.gg/kewN9Gtjt2"},"discord")," and we will help you out.")),(0,a.kt)("p",null,"Welcome to llm-chain, a Rust library designed to simplify working with large language models (LLMs) and help you create powerful applications. In this tutorial, we'll walk you through installing Rust, setting up a new project, and getting started with LLM-Chain."),(0,a.kt)("h2",{id:"installing-rust"},"Installing Rust"),(0,a.kt)("p",null,"To begin, you'll need to install Rust on your machine. We recommend using ",(0,a.kt)("a",{parentName:"p",href:"https://rustup.rs/"},"rustup")," , the official Rust toolchain manager, to ensure you have the latest version and can manage your installations easily."),(0,a.kt)("p",null,"You need Rust 1.65.0 or higher. If you see errors about unstable feature or dependencies requiring newer Rust version, please update your Rust version."),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"Follow the instructions on the ",(0,a.kt)("a",{parentName:"li",href:"https://rustup.rs/"},"rustup website")," to install Rust.")),(0,a.kt)("h2",{id:"creating-a-new-rust-project"},"Creating a New Rust Project"),(0,a.kt)("p",null,"Now that you have Rust installed, it's time to create a new Rust project. Run the following command to set up a new binary project:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"\ncargo new --bin my-llm-project\n")),(0,a.kt)("p",null,"This command will create a new directory called ",(0,a.kt)("inlineCode",{parentName:"p"},"my-llm-project")," with the necessary files and directories for a Rust project."),(0,a.kt)("h2",{id:"installing-llm-chain"},"Installing LLM-Chain"),(0,a.kt)("p",null,"With your Rust project set up, it's time to add LLM-Chain as a dependency. To do this, run the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"\ncd my-llm-project\ncargo add llm-chain\n")),(0,a.kt)("p",null,"This will add LLM-Chain to your project's ",(0,a.kt)("inlineCode",{parentName:"p"},"Cargo.toml")," file."),(0,a.kt)("h2",{id:"choosing-a-driver-llama-vs-openai"},"Choosing a Driver: LLAMA vs OpenAI"),(0,a.kt)("p",null,"LLM-Chain supports multiple drivers for working with different LLMs. You can choose between the LLAMA driver (which runs a LLaMA LLM on your computer) and the OpenAI driver (which connects to the OpenAI API). For ease of use and getting started quickly, we'll be using the OpenAI driver in this tutorial. To install it run"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cargo add llm-chain-openai\n")),(0,a.kt)("p",null,"In the next tutorial, we'll cover generating your first LLM output using the OpenAI driver."))}d.isMDXComponent=!0}}]);