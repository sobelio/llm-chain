[package]
name = "llm-chain"
version = "0.5.0"
edition = "2021"
description = "A library for running chains of LLMs (such as ChatGPT) in series to complete complex tasks, such as text summation."
license = "MIT"
keywords = ["llm", "langchain", "chatgpt", "chain"]
categories = ["science"]
authors = ["William Rudenmalm <william@sobel.io>"]
readme = "../docs/README.md"
repository = "https://github.com/sobelio/llm-chain/"

[features]
default = ["serialization", "tera", "qdrant"]
serialization = ["dep:serde", "dep:serde_yaml", "dep:markdown"]
async = ["dep:tokio"]
tera = ["dep:tera"]
qdrant = ["dep:qdrant-client"]

[dependencies]
anyhow = "1.0.70"
async-trait = "0.1.68"
dynfmt = { version = "0.1.5", features = ["curly"], default-features = false }
futures = "0.3.28"
qdrant-client = { version = "1.1.1", optional = true }
serde = { version = "1.0.160", optional = true, features = ["derive"] }
serde_yaml = { version = "0.9.21", optional = true }
thiserror = "1.0.40"
tokio = { version = "1.27.0", optional = true, features = ["fs", "io-util"] }
markdown = { version = "1.0.0-alpha.7", optional = true }
tera = { version = "1.18.1", optional = true }
lazy_static = "1.4.0"
uuid = { version = "1.3.1", features = ["v4"] }

[dev-dependencies]
tokio = "1.27.0"
